\documentclass[journal]{IEEEtran}

\usepackage{graphicx}

\begin{document}

\title{Reasoning in Artificial Neural Networks}

\author{%
  \IEEEauthorblockN{Vasin Srisupavanich}
}

\maketitle


\begin{abstract}
Over the past decade, deep learning systems have enjoyed tremendous success in the area of computer vision and natural language understanding.
However, these systems still struggle in tasks which require deliberate thinking and reasoning process. 
Recently, many approaches to extends the capability of the neural networks have emerged. 
This paper reviews several recent approaches which takes inspiration from human's cognitive process and symbolic view of artificial intelligence
to solve reasoning tasks, and outline future research directions in this challenging problem.
\end{abstract}

\begin{IEEEkeywords}
deep learning, artificial neural networks, reasoning, attention, memory, graph neural networks, neural-symbolic
\end{IEEEkeywords}

\section{Introduction}

\IEEEPARstart{T}{he} ability to reason is one of the most important features of human intelligence. 
It allows us to understand abstract concepts and make complex decisions.
Human excels at tasks that require deliberate thinking, such as planning and symbol manipulation, 
while the current state of machines are limited to simpler pattern matching problems.
Incorporating reasoning ability to machines has been a long standing goal, but a very difficult challenge in the field of Artificial Intelligence (AI). 
Solving this problem would mean a significant step toward artificial general intelligence, which will ultimately benefits humankind. 
This paper reviews recent approaches in building artificial neural networks (ANN) that can learn to reason, 
and overview the current state of the art results and applications from deep learning systems with reasoning capability.

\section{Background}
According to \cite{bottou2014machine}, reasoning refers to the ability to ``algebraically manipulating previously acquired knowledge in order to answer a new question''.
Historically, the approach to create an AI system capable of reasoning has been from a symbolic point of view.
In a symbolic AI, knowledge is represented as symbols, rules are handcrafted by human, and reasoning is the process of inference.
However, these systems have been overshadowed by the success of deep learning in various domains in the past decades.

Despite the astonishing power of the neural networks, they tend to learn statistical mapping between input and output,
rather than the true causal relations. With the goal to improve deep learning system beyond pattern matching, many researchers have tried to combine symbolic AI with neural networks,
which became a subfield called Neural-symbolic. Apart from that, researchers also take inspiration from neuroscience. 
As human reasoning involves extracting knowledge from memory and paying attention to specific part of information, 
this has resulted in an extension of neural network in the form of memory and attention mechanism. 

\section{Main Approaches}
\subsection{Attention Mechanism}
Attention mechanism was first introduced in 2014 for a machine translation task \cite{bahdanau2014neural}.
Since then this mechanism has became an important tool for deep learning in various applications. 
This idea is loosely motivated by how human biological system works. For instance, human visual attention allows us to 
focus on specific region with high resolution, while ignoring other irrelevant information. 
In the context of machine translation, attention model enables the machine to focus on specific words at a time 
rather than the full sentence.

In a neural machine translation model (NMT), the architecture consists of an encoder-decoder (seq2seq) structure.
An encoder, typically a recurrent neural networks (RNN), learn to encode a source sentence into a fixed length vector.
Then the decoder network output the encoded vector into another language. Figure \ref{NMT}(a) shows the traditional encoder-decoder architecture.
The apparent problem of this architecture is that the model tends to forget relevant information in a long sentence.
With the addition of attention model (figure \ref{NMT}(b)), this problem is mitigated, 
as the decoder can learn to attend to different parts of the source sentence. 
The attention weights, which are from a feed forward neural networks, are jointly train along with the encoder-decoder networks.

\begin{figure}[htb]
  \centering
  \includegraphics[width=0.7\columnwidth]{NMT.png}
  \caption{NMT architecture (a) traditional (b) with attention model.
  Figure from \cite{chaudhari1904attentive}}
  \label{NMT}
\end{figure}

In another influential paper by Xu et al \cite{xu2015show}, attention model is applied to generate caption from images. 
In this task, convolutional neural networks (CNN) is used as an encoder to extract features from raw images.
Then a long short-term memory network (LSTM) is used to generate the words, conditioned on the attention weights.
Figure \ref{attention} demonstrate how the model learn to attend to specific part of the image with the corresponding word. 
Also proposed in \cite{xu2015show}, the attention models can be classified in two types: soft and hard attention. 
In soft attention, the model is smooth and differentiable end to end, and the context vector is computed by the weighted average of the whole image. 
In contrast, in hard attention, the context vector is computed from stochastically sampled patch of image. 
The hard attention model can be faster when making inference, however, they are difficult to optimized, and require reinforcement learning to train.

\begin{figure}[htb]
  \includegraphics[width=\linewidth]{attention.png}
  \caption{Visualization of the attended region conditioned on the corresponding word.
  Figure from \cite{xu2015show}}
  \label{attention}
\end{figure}

\subsection{Memory Augmented Neural Networks}
Similar to human, in order to retrieve the information necessary for the desired tasks, a machine needs to maintain some memory that needs to be efficiently organized and queried. 
This is particularly essential for complex tasks, such as multi-hop reasoning. Traditional RNN and its variant LSTM can memorize information in the hidden states,
however, they are limited to only short term dependencies. Recent approaches to alleviate this issues involves explicit memory representation and the use of external memory, 
as proposed in Neural Turing Machine \cite{graves2014neural} and Memory Networks \cite{weston2014memory}. 

A Neural Turing Machine (NTM) contains two major components: a neural network controller and a memory bank (Figure \ref{NTM}). 
A controller can be any type of neural networks, feed forward or RNN, and is responsible for read and write operations on the memory matrix.
The read and write operations are done selectively by soft attention mechanism, making every components fully differentiable, 
and thereby the whole model can be trained using gradient descent. The experiments reported in \cite{graves2014neural} have shown that NTM significantly
outperforms traditional LSTM in tasks, such as copying and sorting.

\begin{figure}[htb]
  \centering
  \includegraphics[width=0.8\columnwidth]{NTM.png}
  \caption{Architecture of Neural Turing Machine}
  \label{NTM}
\end{figure}

Another recent neural networks model, utilizing both attention and memory, designed to facilitate explicit reasoning is the MAC networks \cite{hudson2018compositional}.
In contrast to NTM, the MAC networks don't utilizing a global external memory. Instead, each node (MAC cell) is recurrent, and has its own memory and control state.
In contrast to traditional neural networks, the separation between control and memory encourages the networks to 
learn the computational process and reasoning operations, rather than to approximate direct transformation between the input and output.
Figure \ref{mac-clevr} shows the result of the MAC networks from a visual reasoning task using CLEVR data set \cite{johnson2017clevr}. 
The MAC networks was able to achieve 98.94\% accuracy, halving the error rate from the best prior model.
\begin{figure}[htb]
  \includegraphics[width=\linewidth]{mac-clevr.png}
  \caption{Example of MAC networks performing novel visual reasoning task. Figure from \cite{hudson2018compositional}}
  \label{mac-clevr}
\end{figure}

\subsection{Neural-Symbolic}

In contrast to the purely sub-symbolic systems mention in the previous approaches, neural-symbolic is the subfield that try to integrate symbolic AI with the deep learning system. 
The idea is that the symbolic part world help the system logically reason about symbols, which is what traditional neural networks are weak at, 
while the neural network part would allow the system to learn, which the symbolic AI is not capable of.

In a visual question answering (VQA) task, recent neural-symbolic system, NS-CL \cite{Mao2019NeuroSymbolic} employed deep representation learning
for visual recognition and language understanding, while the reasoning part is solved by symbolic program execution.
The framework proposed in NS-CL contains three separate modules: 
a visual module where the objects are detected and vector representations are extracted, 
a semantic parser where the question text is parsed into a tree of predefined domain specific language (DSL) of executable program,
and a symbolic program executer which take in the parsed program and vector representation of objects to derive the answer. 

It has been shown that this method requires significantly less amount of training data to accurately answer questions, 
and was able to generalize to new scenes and questions better than traditional neural networks based method. 
Another added benefit of the neural-symbolic system is that the results are fully interpretable, as the execution trace is visible.
Figure \ref{nscl} shows the result of this model on the VQS dataset, along with the generated symbolic program. 
On the other hand, one significantly limitation is that the symbolic functions (DSL) need to be pre-defined. 
As shown in \cite{Mao2019NeuroSymbolic}, functions such as filter, count and query are hard-coded into the system, 
thus this method wouldn't be able to scale in the real-world system.

\begin{figure}[htb]
  \includegraphics[width=\linewidth]{nscl.png}
  \caption{Result of NS-CL on the VQS dataset. Figure from \cite{Mao2019NeuroSymbolic}}
  \label{nscl}
\end{figure}

\subsection{Graph Neural Networks}

Recently, graph neural networks (GNN) has been gaining popularity in various domains, 
particularly in tasks where data are represented as graph with complex relationship and interdependency between objects.
A graph is a data structure consisted of vertices (nodes) and edges.
Depending on the relationship between two objects, the edge can either be directed or undirected. 
In GNN, the node, edge and output can be flexibly represented in different types depending on the tasks. 
For instance, when the input is the image, the node would represent the patch of the image, and
when the text is the input, the node would represent a sequence of words.

It has been shown that GNN is well suited for relational reasoning task, due to the strong relational inductive bias \cite{graphnetworks}.
In contrast to CNN, where the inductive bias is the locality of the receptive field, and RNN where the bias is the sequentiality of data,
GNN can express arbitrary relationship among entities. 
Recent work in \cite{xu2019can} studied what task a neural network can learn to reason. 
The result revealed that the performance of the neural networks increase with more algorithmic alignment in the reasoning process, 
and the reason that GNN generalized better than other types of neural networks in many reasoning tasks is because the underlying reasoning process of GNN resemble dynamic programming.

To illustrate the use of the graph networks, a recent model called Neural State Machine (NSM) \cite{hudson2019learning} utilized graph structure to represent the scene of an image in a VQA task.
This model works in two stages: modeling and inference. 
In the modeling stage, the image is decomposed into a probabilistic graph that capture the semantic of the visual scene.
The node corresponds to object within the image, while the edge represents both spatial and semantic relation.
In the inference stage, the sequential reasoning process is performed over the graph by iteratively traversing its node guided by the question.
Figure \ref{nsm} shows the overall process with the generated scene graph.

\begin{figure}[htb]
  \includegraphics[width=\linewidth]{NSM.png}
  \caption{Overall process of Neural State Machine. Figure from \cite{hudson2019learning}}
  \label{nsm}
\end{figure}

\section{Discussion}

We have seen several approaches in building a neural networks with reasoning capability. 
Each approach has its own strength and weakness.
While the attention mechanism allow the model to focus on specific part of information, this alone cannot be used to solve the reasoning task.
Similar to working memory in the human brain, adding explicit memory to the neural networks give the model the ability to utilize the previous knowledge,
however, the networks with global memory can be difficult to train.
In a neural-symbolic system, the results from the networks are more interpretable, unlike a black box system in a traditional ANN,
but this come with a cost of fixed symbolic function, and can be difficult to scale into the real problem.
In contrast to neural-symbolic system, a graph neural networks can be used to recreate the symbolic structure, 
while maintaining the end to end differentiability. Nevertheless, many problems and processes cannot be easily represented as graph.
There are still a lot of open questions in how to alleviate each of the weakness and combine each of the approach. 
However, I am convince that with the use of attention, memory, and the right inductive prior, 
this is the right step towards making a machine that is more intelligent.

\bibliographystyle{IEEEtran}
\bibliography{references}


\end{document}


