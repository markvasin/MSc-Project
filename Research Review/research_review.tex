\documentclass[journal]{IEEEtran}

\usepackage{graphicx}

\begin{document}

\title{Reasoning in Artificial Neural Networks}

\author{%
  \IEEEauthorblockN{Vasin Srisupavanich}
}

\maketitle


\begin{abstract}
The abstract goes here.
\end{abstract}


\begin{IEEEkeywords}
Deep learning, neural networks, reasoning, graph neural networks, neural-symbolic, neural turing machine
\end{IEEEkeywords}



\section{Introduction}

\IEEEPARstart{T}{he} ability to reason is one of the most important features of human intelligence. 
It allows us to understand abstract concepts and make complex decisions.
Human excels at tasks that require deliberate thinking, such as planning and symbol manipulation, 
while the current state of machines are limited to simpler pattern matching problems.
Incorporating reasoning ability to machines has been a long standing goal, but a very difficult challenge in the field of Artificial Intelligence (AI). 
Solving this problem would mean a significant step toward artificial general intelligence, which will ultimately benefits humankind greatly. 
This paper reviews recent approaches in building artificial neural networks (ANN) that can learn to reason, 
and overview the current state of the art results and applications from deep learning systems with reasoning capability.

\section{Background}
Over the past decade, deep learning systems have enjoyed tremendous success particularly in the area of computer vision and natural language processing.
Machines can now learn to recognize an object in an image with higher accuracy than human, synthesize a novel, and beat a world champion Go player.
However, they still struggle in tasks that involve reasoning operations. For example, deep learning system today have difficulty in
identify cause and effect (causal reasoning), and understanding what is to the left of an object (spatial-temporal reasoning).

Historically, the approach to create an AI system capable of reasoning has been from a symbolic point of view.
In a symbolic AI, knowledge is represented as symbols, rules are handcrafted by human, and reasoning is the process of inference.
However, these systems do not scale to real-world applications, as fixed symbols and rules cannot represents enough information. 
This has paved the way to the current trend of a sub-symbolic deep learning approach, which utilise artificial neural networks. 

With the goal to improve deep learning system beyond pattern matching, AI researchers have tried to combine symbolic AI with neural networks,
which became subfield called Neural-symbolic. Apart from that, researchers also take inspiration from neuroscience. 
As human reasoning involves extracting knowledge from memory and paying attention to specific part of information, 
this has resulted in an extension of neural network in the form of memory and attention mechanism. 

\section{Main Approaches}
\subsection{Attention Mechanism}
Attention mechanism was first introduced in 2014 for a machine translation task \cite{bahdanau2014neural}.
Since then this mechanism has became an important tool for deep learning in various applications. 
This idea is loosely motivated by how human biological system works. For instance, human visual attention allows us to 
focus on specific region with high resolution, while ignoring other irrelevant information. 
In the context of machine translation, attention model enables the machine to focus on specific words at a time 
rather than the full sentence.

In a neural machine translation model (NMT), the architecture consists of an encoder-decoder (seq2seq) structure.
An encoder, typically a recurrent neural networks (RNN), learn to encode a source sentence into a fixed length vector.
Then the decoder network output the encoded vector into another language. Figure \ref{NMT}(a) shows the traditional encoder-decoder architecture.
The apparent problem of this architecture is that the model tends to forget relevant information in a long sentence.
With the addition of attention model (figure \ref{NMT}(b)), this problem is mitigated, 
as the decoder can learn to attend to different parts of the source sentence. 
The attention weights, which are from a feed forward neural networks, are jointly train along with the encoder-decoder networks.

\begin{figure}[htb]
  \includegraphics[width=\linewidth]{../NMT.png}
  \caption{NMT architecture (a) traditional (b) with attention model.
  Figure from \cite{chaudhari1904attentive}}
  \label{NMT}
\end{figure}

In another influential paper by Xu et al \cite{xu2015show}, attention model is applied to generate caption from images. 
In this task, convolutional neural networks (CNN) is used as an encoder to extract features from raw images.
Then a long short-term memory network (LSTM) is used to generate the words, conditioned on the attention weights.
Figure \ref{attention} demonstrate how the model learn to attend to specific part of the image with the corresponding word. 
Also proposed in \cite{xu2015show}, the attention models can be classified in two types: soft and hard attention. 
In soft attention, the model is smooth and differentiable end to end, and the context vector is computed by the weighted average of the whole image. 
In contrast, in hard attention, the context vector is computed from stochastically sampled patch of image. 
The hard attention model can be faster when making inference, however, they are difficult to optimized, and require reinforcement learning to train.

\begin{figure}[htb]
  \includegraphics[width=\linewidth]{../attention.png}
  \caption{Visualization of the attended region conditioned on the corresponding word.
  Figure from \cite{xu2015show}}
  \label{attention}
\end{figure}

\subsection{Memory Augmented Neural Networks}
Similar to human, in order to retrieve the information necessary for the desired tasks, a machine needs to maintain some memory that needs to be efficiently organized and queried. 
This is particularly essential for complex tasks, such as multi-hop reasoning. Traditional RNN and its variant LSTM can memorize information in the hidden states,
however, they are limited to only short term dependencies. Recent approaches to alleviate this issues involves explicit memory representation and the use of external memory, 
as proposed in Neural Turing Machine \cite{graves2014neural} and Memory Networks \cite{weston2014memory}.

A Neural Turing Machine (NTM) contains two major components: a neural network controller and a memory bank (Figure \ref{NTM}). 
A controller can be any type of neural networks, feed forward or RNN, and is responsible for read and write operations on the memory matrix.
The read and write operations are done selectively by soft attention mechanism, making every components fully differentiable, 
and thereby the whole model can be trained using gradient descent. The experiments reported in \cite{graves2014neural} have shown that NTM significantly
outperforms traditional LSTM in tasks, such as copying and sorting. Memory networks \cite{graves2014neural} are similar to NTM in the sense that they both utilise external memory, attention mechanism to select information from memory, and
can be trained end to end with gradient based learning. However, one major difference is that the memory cells in the memory networks are more static, 
as controller in memory networks only allowed read operation.

\begin{figure}[htb]
  \includegraphics[width=\linewidth]{../NTM.png}
  \caption{Architecture of Neural Turing Machine}
  \label{NTM}
\end{figure}

Another recent neural networks model, utilizing both attention and memory, designed to facilitate explicit reasoning is the MAC networks \cite{hudson2018compositional}.
In contrast to NTM, the MAC networks don't utilizing a global external memory. Instead, each node (MAC cell) is recurrent, and has its own memory and control state.
In contrast to traditional neural networks, the separation between control and memory encourages the networks to 
learn the computational process and reasoning operations, rather than to approximate direct transformation between the input and output.

\subsection{Graph Neural Networks}

\subsection{Neural-Symbolic}

\section{Discussion}

\section{Conclusion}

\bibliographystyle{IEEEtran}
\bibliography{references}


\end{document}


